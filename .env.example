# LLM Router Environment Configuration
# Copy this file to .env for development or .env.production for production

# Server Configuration
NODE_ENV=development
PORT=3006
HOST=0.0.0.0

# Security - CORS Origins (comma-separated)
# For production, use your actual domain
ALLOWED_ORIGINS=http://localhost:3006,http://localhost:8080

# API Keys (comma-separated) - Generate strong keys for production
# Example: openssl rand -hex 32
API_KEYS=dev-key-123456789,test-key-987654321

# Rate Limiting
RATE_LIMIT_WINDOW=900000  # 15 minutes in milliseconds
RATE_LIMIT_MAX=100        # Max requests per window

# Model Configuration
MAX_MODEL_SIZE=2000000000  # 2GB in bytes
MAX_CONCURRENT=10          # Max concurrent inference requests
ROUTING_STRATEGY=balanced  # balanced, quality-first, speed-priority, cost-optimized

# CPU Optimization Settings
# For a 3 vCPU server, use 2 threads to leave headroom for system processes
LLM_MAX_THREADS=2

# Memory Optimization
# Smaller context size uses less RAM (default 2048)
LLM_CONTEXT_SIZE=2048

# Batch size for inference (smaller = less CPU usage, slower throughput)
LLM_BATCH_SIZE=8

# Caching
CACHE_ENABLED=true
CACHE_TTL=300000  # 5 minutes in milliseconds

# Logging
LOG_LEVEL=info  # error, warn, info, debug

# Performance Monitoring
ENABLE_METRICS=true

# Session Security (generate with: openssl rand -hex 32)
SESSION_SECRET=your-session-secret-here

# Optional: Error Tracking
# SENTRY_DSN=your-sentry-dsn-here

# Optional: Analytics
# GA_TRACKING_ID=your-google-analytics-id

# Optional: CDN
# CDN_URL=https://cdn.yourdomain.com

# Optional: Database (for persistent storage)
# DATABASE_URL=postgresql://user:password@localhost:5432/llm_router

# Optional: Redis (for distributed caching)
# REDIS_URL=redis://localhost:6379

# Optional: Model Registry URL
# MODEL_REGISTRY_URL=https://your-model-registry.com/api

# Optional: Webhook for monitoring
# WEBHOOK_URL=https://your-monitoring-service.com/webhook
# WEBHOOK_SECRET=your-webhook-secret