<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: loaders/BinaryLoader.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: loaders/BinaryLoader.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * 📦 Binary Model Loader
 * Generic loader for .bin model files (supports multiple formats)
 */

import { ModelInterface } from '../core/ModelInterface.js';
import { Logger } from '../utils/Logger.js';
import path from 'path';
import fs from 'fs/promises';

const logger = new Logger('BinaryLoader');

/**
 * Binary Model implementation
 * Handles generic .bin files which could be various model formats
 */
class BinaryModel extends ModelInterface {
  constructor(config) {
    super(config);
    this.format = 'binary';
    this.source = config.source || config.path;
    this.model = null;
    this.modelType = null;
    
    // Try to detect the actual format from metadata or naming
    this.detectedFormat = this.detectFormat(config);
    
    // Model configuration
    this.maxLength = parseInt(config.maxLength || 512);
    this.temperature = parseFloat(config.temperature || 0.7);
    this.topP = parseFloat(config.topP || 0.9);
  }

  /**
   * Attempt to detect the actual model format
   */
  detectFormat(config) {
    const source = (config.source || config.path || '').toLowerCase();
    const name = (config.name || '').toLowerCase();
    
    // Check for known patterns in filenames
    if (source.includes('pytorch_model.bin') || name.includes('pytorch')) {
      return 'pytorch';
    }
    if (source.includes('tf_model.bin') || name.includes('tensorflow')) {
      return 'tensorflow';
    }
    if (source.includes('flax_model.bin') || name.includes('flax')) {
      return 'flax';
    }
    if (source.includes('onnx') || name.includes('onnx')) {
      return 'onnx';
    }
    if (source.includes('ggml') || name.includes('ggml')) {
      return 'ggml';
    }
    
    // Check for model architecture hints
    if (name.includes('bert')) return 'bert';
    if (name.includes('gpt')) return 'gpt';
    if (name.includes('llama')) return 'llama';
    if (name.includes('t5')) return 't5';
    
    return 'unknown';
  }

  async load() {
    if (this.loaded) return;
    
    logger.info(`📦 Loading Binary model: ${this.name}`);
    logger.info(`  Source path: ${this.source}`);
    logger.info(`  Detected format: ${this.detectedFormat}`);
    this.loading = true;
    
    try {
      // Resolve model path
      const modelPath = path.isAbsolute(this.source) 
        ? this.source 
        : path.resolve(process.cwd(), this.source);
      
      logger.info(`  Resolved path: ${modelPath}`);
      
      // Check if file exists
      await fs.access(modelPath);
      
      // Get file stats
      const stats = await fs.stat(modelPath);
      const sizeInMB = (stats.size / (1024 * 1024)).toFixed(2);
      logger.info(`  Model size: ${sizeInMB} MB`);
      
      // Read first few bytes to check for magic numbers
      const fileHandle = await fs.open(modelPath, 'r');
      const buffer = Buffer.alloc(16);
      await fileHandle.read(buffer, 0, 16, 0);
      await fileHandle.close();
      
      // Check for known file signatures
      let fileSignature = 'unknown';
      
      // PyTorch format check (ZIP file signature)
      if (buffer[0] === 0x50 &amp;&amp; buffer[1] === 0x4B) {
        fileSignature = 'pytorch-zip';
        this.detectedFormat = 'pytorch';
      }
      // ONNX format check
      else if (buffer.toString('utf8', 0, 4) === '\x08\x01\x12\x00') {
        fileSignature = 'onnx';
        this.detectedFormat = 'onnx';
      }
      // GGML format check
      else if (buffer.toString('utf8', 0, 4) === 'ggml') {
        fileSignature = 'ggml';
        this.detectedFormat = 'ggml';
      }
      
      logger.info(`  File signature: ${fileSignature}`);
      
      // Store model metadata
      this.modelMetadata = {
        path: modelPath,
        size: stats.size,
        sizeInMB: sizeInMB,
        format: this.detectedFormat,
        signature: fileSignature,
        lastModified: stats.mtime
      };
      
      // Check if we have a companion config file
      const configPath = modelPath.replace('.bin', '.json');
      try {
        await fs.access(configPath);
        const configData = await fs.readFile(configPath, 'utf8');
        const config = JSON.parse(configData);
        this.modelConfig = config;
        logger.info(`  Found config file: ${path.basename(configPath)}`);
        
        // Extract useful information from config
        if (config.model_type) {
          this.modelType = config.model_type;
          logger.info(`  Model type: ${this.modelType}`);
        }
        if (config.architectures) {
          this.architectures = config.architectures;
          logger.info(`  Architectures: ${config.architectures.join(', ')}`);
        }
      } catch (error) {
        logger.debug('No companion config file found');
      }
      
      // Note: Actual inference would require format-specific handling
      logger.warn(`Binary model loaded as metadata only - ${this.detectedFormat} inference requires specific implementation`);
      
      this.loaded = true;
      this.loading = false;
      this.metrics.loadTime = Date.now();
      
      logger.success(`✅ Binary model registered: ${this.name} (${this.detectedFormat})`);
    } catch (error) {
      this.error = error;
      this.loading = false;
      logger.error(`❌ Failed to load Binary model: ${error.message}`);
      throw error;
    }
  }

  async unload() {
    if (!this.loaded) return;
    
    logger.info(`📦 Unloading Binary model: ${this.name}`);
    
    this.model = null;
    this.modelConfig = null;
    this.loaded = false;
    
    logger.success(`✅ Binary model unloaded: ${this.name}`);
  }

  async generate(prompt, options = {}) {
    if (!this.loaded) {
      throw new Error('Model not loaded');
    }
    
    const config = {
      maxLength: options.maxLength || this.maxLength,
      temperature: options.temperature || this.temperature,
      topP: options.topP || this.topP,
      ...options
    };
    
    logger.info(`📦 Generating with Binary model: ${this.name}`);
    
    // Provide format-specific guidance
    let guidance = '';
    switch (this.detectedFormat) {
      case 'pytorch':
        guidance = 'This appears to be a PyTorch model. Consider using the PyTorchLoader for better support.';
        break;
      case 'onnx':
        guidance = 'This appears to be an ONNX model. Consider using the ONNXLoader for inference.';
        break;
      case 'tensorflow':
        guidance = 'This appears to be a TensorFlow model. TensorFlow.js support can be added.';
        break;
      case 'ggml':
        guidance = 'This appears to be a GGML model. Consider converting to GGUF format.';
        break;
      default:
        guidance = 'Format detection can be improved with model metadata.';
    }
    
    // Placeholder response with model information
    const response = {
      text: `[Binary Model Response - Format: ${this.detectedFormat}]\n` +
            `Model: ${this.name}\n` +
            `Size: ${this.modelMetadata.sizeInMB} MB\n` +
            `Type: ${this.modelType || 'Unknown'}\n` +
            `Prompt: ${prompt}\n\n` +
            `Note: ${guidance}`,
      usage: {
        promptTokens: prompt.length / 4,
        completionTokens: 75,
        totalTokens: prompt.length / 4 + 75
      },
      model: this.name,
      metadata: this.modelMetadata
    };
    
    // Update metrics
    this.metrics.inferenceCount++;
    this.metrics.totalTokens += response.usage.totalTokens;
    this.metrics.lastUsed = new Date().toISOString();
    
    return response;
  }

  async *stream(prompt, options = {}) {
    if (!this.loaded) {
      throw new Error('Model not loaded');
    }
    
    logger.info(`📦 Streaming with Binary model: ${this.name}`);
    
    // Placeholder streaming implementation
    const info = `[Binary Model Streaming - ${this.detectedFormat} format detected]`;
    const words = info.split(' ');
    
    for (const word of words) {
      yield {
        token: word + ' ',
        done: false
      };
      
      // Simulate processing time
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    yield { done: true };
  }

  getInfo() {
    return {
      ...super.getInfo(),
      format: 'binary',
      detectedFormat: this.detectedFormat,
      modelType: this.modelType,
      architectures: this.architectures,
      metadata: this.modelMetadata,
      modelConfig: this.modelConfig,
      capabilities: {
        ...this.capabilities,
        streaming: true,
        formats: ['.bin']
      }
    };
  }
}

/**
 * Binary Loader - Handles generic .bin files
 */
class BinaryLoader {
  constructor(config = {}) {
    this.config = config;
    this.models = new Map();
  }

  /**
   * Check if this loader can handle the given source
   */
  canHandle(source) {
    if (typeof source === 'string') {
      return source.toLowerCase().endsWith('.bin');
    }
    return source?.format === 'binary' || source?.format === 'bin';
  }

  /**
   * Load a Binary model
   */
  async load(source, options = {}) {
    logger.info('📦 BinaryLoader: Loading model from source', { source });
    
    const modelConfig = {
      id: options.id || `binary-${Date.now()}`,
      name: options.name || path.basename(source, '.bin'),
      source: source,
      path: source,
      format: 'binary',
      ...options
    };
    
    const model = new BinaryModel(modelConfig);
    await model.load();
    
    this.models.set(model.id, model);
    return model;
  }

  /**
   * Unload a model
   */
  async unload(modelId) {
    const model = this.models.get(modelId);
    if (model) {
      await model.unload();
      this.models.delete(modelId);
    }
  }

  /**
   * Get all loaded models
   */
  getModels() {
    return Array.from(this.models.values());
  }

  /**
   * Get loader info
   */
  getInfo() {
    return {
      name: 'BinaryLoader',
      version: '1.0.0',
      formats: ['.bin'],
      capabilities: {
        streaming: true,
        quantization: false,
        formatDetection: true,
        metadataExtraction: true
      },
      supportedFormats: [
        'pytorch_model.bin',
        'tf_model.bin',
        'flax_model.bin',
        'model.bin',
        'weights.bin'
      ],
      modelsLoaded: this.models.size
    };
  }
}

export default BinaryLoader;
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="ABTestingManager.html">ABTestingManager</a></li><li><a href="APILoader.html">APILoader</a></li><li><a href="AnthropicAdapter.html">AnthropicAdapter</a></li><li><a href="AuditLogger.html">AuditLogger</a></li><li><a href="AuthManager.html">AuthManager</a></li><li><a href="AuthMiddleware.html">AuthMiddleware</a></li><li><a href="AzureOpenAIAdapter.html">AzureOpenAIAdapter</a></li><li><a href="BPETokenizer.html">BPETokenizer</a></li><li><a href="BaseEngine.html">BaseEngine</a></li><li><a href="BaseLoader.html">BaseLoader</a></li><li><a href="BedrockAdapter.html">BedrockAdapter</a></li><li><a href="BinaryLoader.html">BinaryLoader</a></li><li><a href="BinaryModel.html">BinaryModel</a></li><li><a href="BitNetLoader.html">BitNetLoader</a></li><li><a href="CohereAdapter.html">CohereAdapter</a></li><li><a href="ConversionConfig.html">ConversionConfig</a></li><li><a href="ConversionResult.html">ConversionResult</a></li><li><a href="DeepSeekAdapter.html">DeepSeekAdapter</a></li><li><a href="EnterpriseAuthManager.html">EnterpriseAuthManager</a></li><li><a href="EnterpriseManager.html">EnterpriseManager</a></li><li><a href="EnterpriseRouter.html">EnterpriseRouter</a></li><li><a href="ErrorHandler.html">ErrorHandler</a></li><li><a href="FireworksAdapter.html">FireworksAdapter</a></li><li><a href="FormatConverter.html">FormatConverter</a></li><li><a href="GGUFLoader.html">GGUFLoader</a></li><li><a href="GGUFModel.html">GGUFModel</a></li><li><a href="GRPCClient.html">GRPCClient</a></li><li><a href="GroqAdapter.html">GroqAdapter</a></li><li><a href="LLMRouter.html">LLMRouter</a></li><li><a href="MistralAdapter.html">MistralAdapter</a></li><li><a href="MockLoader.html">MockLoader</a></li><li><a href="MockModel.html">MockModel</a></li><li><a href="ModelError.html">ModelError</a></li><li><a href="ModelInterface.html">ModelInterface</a></li><li><a href="ModelQuantizer.html">ModelQuantizer</a></li><li><a href="ModelRegistry.html">ModelRegistry</a></li><li><a href="ModelTemplates.html">ModelTemplates</a></li><li><a href="MultiTenancyManager.html">MultiTenancyManager</a></li><li><a href="NovitaAdapter.html">NovitaAdapter</a></li><li><a href="OpenAIAdapter.html">OpenAIAdapter</a></li><li><a href="OpenRouterAdapter.html">OpenRouterAdapter</a></li><li><a href="PerplexityAdapter.html">PerplexityAdapter</a></li><li><a href="Pipeline.html">Pipeline</a></li><li><a href="PyTorchLoader.html">PyTorchLoader</a></li><li><a href="PyTorchModel.html">PyTorchModel</a></li><li><a href="QuantizationConfig.html">QuantizationConfig</a></li><li><a href="QuantizationResult.html">QuantizationResult</a></li><li><a href="Router.html">Router</a></li><li><a href="SLAMonitor.html">SLAMonitor</a></li><li><a href="SentencePieceTokenizer.html">SentencePieceTokenizer</a></li><li><a href="SimpleLoader.html">SimpleLoader</a></li><li><a href="SimpleModel.html">SimpleModel</a></li><li><a href="TogetherAdapter.html">TogetherAdapter</a></li><li><a href="TokenizationResult.html">TokenizationResult</a></li><li><a href="TokenizerConfig.html">TokenizerConfig</a></li><li><a href="UniversalTokenizer.html">UniversalTokenizer</a></li><li><a href="ValidationConfig.html">ValidationConfig</a></li><li><a href="ValidationSuite.html">ValidationSuite</a></li><li><a href="ValidationSuiteResult.html">ValidationSuiteResult</a></li><li><a href="ValidationTestResult.html">ValidationTestResult</a></li><li><a href="VertexAIAdapter.html">VertexAIAdapter</a></li><li><a href="WordPieceTokenizer.html">WordPieceTokenizer</a></li></ul><h3>Global</h3><ul><li><a href="global.html#ADAPTER_REGISTRY">ADAPTER_REGISTRY</a></li><li><a href="global.html#API_KEY_PATTERNS">API_KEY_PATTERNS</a></li><li><a href="global.html#AUTH_TYPES">AUTH_TYPES</a></li><li><a href="global.html#AZURE_API_VERSIONS">AZURE_API_VERSIONS</a></li><li><a href="global.html#AZURE_OPENAI_MODELS">AZURE_OPENAI_MODELS</a></li><li><a href="global.html#Architectures">Architectures</a></li><li><a href="global.html#AuditEventTypes">AuditEventTypes</a></li><li><a href="global.html#AuthMethods">AuthMethods</a></li><li><a href="global.html#BEDROCK_MODELS">BEDROCK_MODELS</a></li><li><a href="global.html#BreachSeverity">BreachSeverity</a></li><li><a href="global.html#CLAUDE_MODELS">CLAUDE_MODELS</a></li><li><a href="global.html#COHERE_MODELS">COHERE_MODELS</a></li><li><a href="global.html#COMPLIANCE_FEATURES">COMPLIANCE_FEATURES</a></li><li><a href="global.html#Capabilities">Capabilities</a></li><li><a href="global.html#ComplianceFrameworks">ComplianceFrameworks</a></li><li><a href="global.html#DEEPSEEK_ENDPOINTS">DEEPSEEK_ENDPOINTS</a></li><li><a href="global.html#DEEPSEEK_MODELS">DEEPSEEK_MODELS</a></li><li><a href="global.html#EnterpriseFeatures">EnterpriseFeatures</a></li><li><a href="global.html#ExperimentStatus">ExperimentStatus</a></li><li><a href="global.html#FIREWORKS_MODELS">FIREWORKS_MODELS</a></li><li><a href="global.html#GROQ_MODELS">GROQ_MODELS</a></li><li><a href="global.html#INPUT_TYPES">INPUT_TYPES</a></li><li><a href="global.html#IsolationLevels">IsolationLevels</a></li><li><a href="global.html#MISTRAL_MODELS">MISTRAL_MODELS</a></li><li><a href="global.html#MODEL_CATEGORIES">MODEL_CATEGORIES</a></li><li><a href="global.html#ModelFormat">ModelFormat</a></li><li><a href="global.html#ModelFormats">ModelFormats</a></li><li><a href="global.html#NOVITA_ENDPOINTS">NOVITA_ENDPOINTS</a></li><li><a href="global.html#NOVITA_MODELS">NOVITA_MODELS</a></li><li><a href="global.html#OPENAI_MODELS">OPENAI_MODELS</a></li><li><a href="global.html#PERPLEXITY_MODELS">PERPLEXITY_MODELS</a></li><li><a href="global.html#POPULAR_MODELS">POPULAR_MODELS</a></li><li><a href="global.html#PROVIDER_AUTH_CONFIG">PROVIDER_AUTH_CONFIG</a></li><li><a href="global.html#PROVIDER_CATEGORIES">PROVIDER_CATEGORIES</a></li><li><a href="global.html#PROVIDER_CONFIGS">PROVIDER_CONFIGS</a></li><li><a href="global.html#PROVIDER_FEATURES">PROVIDER_FEATURES</a></li><li><a href="global.html#Permissions">Permissions</a></li><li><a href="global.html#QuantizationMethod">QuantizationMethod</a></li><li><a href="global.html#QuantizationPrecision">QuantizationPrecision</a></li><li><a href="global.html#QuotaTypes">QuotaTypes</a></li><li><a href="global.html#RiskLevels">RiskLevels</a></li><li><a href="global.html#RoutingStrategies">RoutingStrategies</a></li><li><a href="global.html#SAFETY_LEVELS">SAFETY_LEVELS</a></li><li><a href="global.html#SLAMetricTypes">SLAMetricTypes</a></li><li><a href="global.html#SLAStatus">SLAStatus</a></li><li><a href="global.html#SessionTypes">SessionTypes</a></li><li><a href="global.html#SplittingAlgorithms">SplittingAlgorithms</a></li><li><a href="global.html#StatisticalTests">StatisticalTests</a></li><li><a href="global.html#TOGETHER_MODELS">TOGETHER_MODELS</a></li><li><a href="global.html#TimeWindows">TimeWindows</a></li><li><a href="global.html#TokenizerType">TokenizerType</a></li><li><a href="global.html#UserRoles">UserRoles</a></li><li><a href="global.html#VERTEX_AI_MODELS">VERTEX_AI_MODELS</a></li><li><a href="global.html#VERTEX_REGIONS">VERTEX_REGIONS</a></li><li><a href="global.html#ValidationSeverity">ValidationSeverity</a></li><li><a href="global.html#ValidationTestType">ValidationTestType</a></li><li><a href="global.html#adjustTimeouts">adjustTimeouts</a></li><li><a href="global.html#attemptRecovery">attemptRecovery</a></li><li><a href="global.html#checkConnectivity">checkConnectivity</a></li><li><a href="global.html#clearCache">clearCache</a></li><li><a href="global.html#colors">colors</a></li><li><a href="global.html#createAdapter">createAdapter</a></li><li><a href="global.html#createEnterpriseExpressRoutes">createEnterpriseExpressRoutes</a></li><li><a href="global.html#createEnterpriseRouter">createEnterpriseRouter</a></li><li><a href="global.html#createEnterpriseWebSocketHandlers">createEnterpriseWebSocketHandlers</a></li><li><a href="global.html#createMissingResources">createMissingResources</a></li><li><a href="global.html#defaultEnterpriseConfig">defaultEnterpriseConfig</a></li><li><a href="global.html#emergencyShutdown">emergencyShutdown</a></li><li><a href="global.html#enterpriseVersion">enterpriseVersion</a></li><li><a href="global.html#errorMonitoringMiddleware">errorMonitoringMiddleware</a></li><li><a href="global.html#escalateError">escalateError</a></li><li><a href="global.html#executeRecovery">executeRecovery</a></li><li><a href="global.html#getAdapter">getAdapter</a></li><li><a href="global.html#getEnabledFeatures">getEnabledFeatures</a></li><li><a href="global.html#getMonitoringStatus">getMonitoringStatus</a></li><li><a href="global.html#getProviderAuthType">getProviderAuthType</a></li><li><a href="global.html#getProviderInfo">getProviderInfo</a></li><li><a href="global.html#getProvidersByCategory">getProvidersByCategory</a></li><li><a href="global.html#getProvidersByFeature">getProvidersByFeature</a></li><li><a href="global.html#getStats">getStats</a></li><li><a href="global.html#getSupportedProviders">getSupportedProviders</a></li><li><a href="global.html#gracefulShutdown">gracefulShutdown</a></li><li><a href="global.html#handleCriticalError">handleCriticalError</a></li><li><a href="global.html#handleMemoryLeak">handleMemoryLeak</a></li><li><a href="global.html#httpMonitoringMiddleware">httpMonitoringMiddleware</a></li><li><a href="global.html#isFeatureEnabled">isFeatureEnabled</a></li><li><a href="global.html#isProviderSupported">isProviderSupported</a></li><li><a href="global.html#logError">logError</a></li><li><a href="global.html#performHealthCheck">performHealthCheck</a></li><li><a href="global.html#recordCustomMetric">recordCustomMetric</a></li><li><a href="global.html#registerAlertRule">registerAlertRule</a></li><li><a href="global.html#registerDependency">registerDependency</a></li><li><a href="global.html#registerHealthCheck">registerHealthCheck</a></li><li><a href="global.html#reinstallDependencies">reinstallDependencies</a></li><li><a href="global.html#reload">reload</a></li><li><a href="global.html#restartProcess">restartProcess</a></li><li><a href="global.html#retryConnection">retryConnection</a></li><li><a href="global.html#selectRecoveryStrategy">selectRecoveryStrategy</a></li><li><a href="global.html#setupHandlers">setupHandlers</a></li><li><a href="global.html#setupMonitoring">setupMonitoring</a></li><li><a href="global.html#softRestart">softRestart</a></li><li><a href="global.html#startHealthMonitoring">startHealthMonitoring</a></li><li><a href="global.html#startPerformanceProfile">startPerformanceProfile</a></li><li><a href="global.html#validateEnterpriseConfig">validateEnterpriseConfig</a></li><li><a href="global.html#withCacheMonitoring">withCacheMonitoring</a></li><li><a href="global.html#withDatabaseMonitoring">withDatabaseMonitoring</a></li><li><a href="global.html#withModelMonitoring">withModelMonitoring</a></li><li><a href="global.html#withQueueMonitoring">withQueueMonitoring</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 4.0.4</a> on Wed Aug 20 2025 19:41:21 GMT+0000 (Coordinated Universal Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
