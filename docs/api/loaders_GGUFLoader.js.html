<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: loaders/GGUFLoader.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: loaders/GGUFLoader.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * ðŸ§  GGUF Model Loader - Production Implementation
 * Real inference using node-llama-cpp v3
 */

import { ModelInterface } from '../core/ModelInterface.js';
import { Logger } from '../utils/Logger.js';
import { fileURLToPath } from 'url';
import path from 'path';
import fs from 'fs/promises';

// Make node-llama-cpp optional
let getLlama, LlamaChatSession;
try {
  const llamaCpp = await import('node-llama-cpp');
  getLlama = llamaCpp.getLlama;
  LlamaChatSession = llamaCpp.LlamaChatSession;
} catch (error) {
  console.warn('node-llama-cpp not available - GGUF models will not be functional');
}

const logger = new Logger('GGUFLoader');

/**
 * GGUF Model - Production implementation with real inference
 */
class GGUFModel extends ModelInterface {
  constructor(config) {
    super(config);
    this.format = 'gguf';
    this.source = config.source || config.path; // Store the model path
    this.model = null;
    this.context = null;
    this.session = null;
    this.llama = null;
    
    // CPU optimization settings
    this.maxThreads = parseInt(config.maxThreads || process.env.LLM_MAX_THREADS || 2);
    this.contextSize = parseInt(config.contextSize || process.env.LLM_CONTEXT_SIZE || 2048);
    this.batchSize = parseInt(config.batchSize || process.env.LLM_BATCH_SIZE || 8);
  }

  async load() {
    if (this.loaded) return;
    
    logger.info(`ðŸ§  Loading GGUF model: ${this.name}`);
    logger.info(`  Source path: ${this.source}`);
    this.loading = true;
    
    try {
      // Check if node-llama-cpp is available
      if (!getLlama) {
        throw new Error('node-llama-cpp is not installed. GGUF models require node-llama-cpp to function.');
      }
      
      // Get llama instance
      this.llama = await getLlama();
      
      // Resolve model path - handle both relative and absolute paths
      const modelPath = path.isAbsolute(this.source) 
        ? this.source 
        : path.resolve(process.cwd(), this.source);
      
      logger.info(`  Resolved path: ${modelPath}`);
      
      // Check if file exists
      await fs.access(modelPath);
      
      // Load the model
      this.model = await this.llama.loadModel({
        modelPath: modelPath,
        gpuLayers: 0 // CPU only for now, can be configured
      });
      
      // Create context with CPU optimization for VPS
      // Limit threads to leave headroom for system processes
      const cpuCount = (await import('os')).default.cpus().length;
      const optimalThreads = Math.max(1, Math.min(cpuCount - 1, this.maxThreads)); // Use configured max threads
      
      logger.info(`  CPU optimization: ${cpuCount} CPUs detected, using ${optimalThreads} threads`);
      
      this.context = await this.model.createContext({
        contextSize: this.contextSize,
        threads: optimalThreads,
        batchSize: this.batchSize // Smaller batch size for lower CPU usage
      });
      
      // Create a chat session
      this.session = new LlamaChatSession({
        contextSequence: this.context.getSequence(),
        systemPrompt: "You are a helpful AI assistant."
      });
      
      this.loaded = true;
      this.loading = false;
      this.metrics.loadTime = Date.now();
      
      logger.success(`âœ… GGUF model loaded: ${this.name}`);
    } catch (error) {
      this.error = error;
      this.loading = false;
      logger.error(`Failed to load GGUF model: ${error.message}`);
      throw error;
    }
  }

  async generate(prompt, options = {}) {
    if (!this.loaded) await this.load();
    
    const startTime = Date.now();
    
    try {
      // Update metrics
      this.metrics.inferenceCount++;
      this.metrics.lastUsed = new Date();
      
      // Generate response
      const response = await this.session.prompt(prompt, {
        maxTokens: options.maxTokens || 500,
        temperature: options.temperature || 0.7,
        topK: options.topK || 40,
        topP: options.topP || 0.95,
        repeatPenalty: options.repeatPenalty || 1.1,
        stopStrings: options.stopStrings || []
      });
      
      // Calculate metrics
      const endTime = Date.now();
      const latency = endTime - startTime;
      const tokens = response.split(/\s+/).length; // Approximate token count
      
      this.metrics.totalTokens += tokens;
      this.metrics.avgLatency = 
        (this.metrics.avgLatency * (this.metrics.inferenceCount - 1) + latency) / 
        this.metrics.inferenceCount;
      
      return {
        text: response,
        tokens,
        latency,
        model: this.name
      };
    } catch (error) {
      logger.error(`Generation failed: ${error.message}`);
      throw error;
    }
  }

  async *stream(prompt, options = {}) {
    if (!this.loaded) await this.load();
    
    const startTime = Date.now();
    let totalTokens = 0;
    
    try {
      // Update metrics
      this.metrics.inferenceCount++;
      this.metrics.lastUsed = new Date();
      
      // Stream response tokens
      const stream = this.session.promptStream(prompt, {
        maxTokens: options.maxTokens || 500,
        temperature: options.temperature || 0.7,
        topK: options.topK || 40,
        topP: options.topP || 0.95,
        repeatPenalty: options.repeatPenalty || 1.1
      });
      
      for await (const chunk of stream) {
        totalTokens++;
        yield chunk;
      }
      
      // Update metrics
      const endTime = Date.now();
      const latency = endTime - startTime;
      
      this.metrics.totalTokens += totalTokens;
      this.metrics.avgLatency = 
        (this.metrics.avgLatency * (this.metrics.inferenceCount - 1) + latency) / 
        this.metrics.inferenceCount;
      
    } catch (error) {
      logger.error(`Streaming failed: ${error.message}`);
      throw error;
    }
  }

  async unload() {
    try {
      if (this.session) {
        this.session = null;
      }
      if (this.context) {
        await this.context.dispose();
        this.context = null;
      }
      if (this.model) {
        await this.model.dispose();
        this.model = null;
      }
      this.loaded = false;
      logger.info(`ðŸ“¦ GGUF model unloaded: ${this.name}`);
    } catch (error) {
      logger.error(`Cleanup failed: ${error.message}`);
    }
  }

  // Override toJSON to include source
  toJSON() {
    const json = super.toJSON();
    json.source = this.source;
    json.path = this.source; // Include both for compatibility
    return json;
  }
}

/**
 * GGUF Loader - The quantum gateway to quantized models
 */
class GGUFLoader {
  static format = 'gguf';
  static extensions = ['.gguf', '.ggml', '.bin'];

  async canLoad(path) {
    const ext = path.split('.').pop().toLowerCase();
    return GGUFLoader.extensions.includes(`.${ext}`);
  }

  async load(spec) {
    logger.info(`ðŸ”® Loading GGUF model from: ${spec.source}`);
    
    // Detect model properties
    const config = await this.detectConfig(spec);
    
    // Create model instance
    const model = new GGUFModel(config);
    
    // Load if immediate loading requested
    if (spec.immediate !== false) {
      await model.load();
    }
    
    return model;
  }

  async detectConfig(spec) {
    // Parse model name and properties from path/spec
    const config = {
      id: spec.id || this.generateId(),
      name: spec.name || this.extractName(spec.source),
      source: spec.source,
      quantization: spec.quantization || this.detectQuantization(spec.source || ''),
      context: spec.context || 2048
    };
    
    // Try to detect architecture
    if (spec.source &amp;&amp; spec.source.includes('llama')) {
      config.architecture = { type: 'llama' };
    } else if (spec.source &amp;&amp; spec.source.includes('mistral')) {
      config.architecture = { type: 'mistral' };
    }
    
    return config;
  }

  extractName(source) {
    // Extract name from path
    if (!source) return 'unknown';
    const parts = source.split('/');
    const filename = parts[parts.length - 1];
    return filename.replace(/\.(gguf|ggml|bin)$/i, '');
  }

  detectQuantization(source) {
    // Detect quantization from filename
    if (!source) return 'q4_k_m';
    const quants = ['q4_0', 'q4_1', 'q4_k_m', 'q4_k_s', 'q5_0', 'q5_1', 'q5_k_m', 'q5_k_s', 'q8_0'];
    
    for (const q of quants) {
      if (source.includes(q)) return q;
    }
    
    return 'q4_k_m'; // default
  }

  async validate(model) {
    // Validate GGUF model
    if (!model.weights) {
      throw new Error('GGUF model missing weights');
    }
    
    if (!model.vocab) {
      throw new Error('GGUF model missing vocabulary');
    }
    
    return true;
  }

  async optimize(model, options) {
    // Optimize GGUF model
    if (options.quantization) {
      await this.requantize(model, options.quantization);
    }
    
    return model;
  }

  async requantize(model, level) {
    logger.info(`âš¡ Requantizing model to ${level}`);
    // Implementation would convert between quantization levels
    model.quantization = level;
  }

  generateId() {
    return `gguf_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  async fromData(data) {
    // Restore model from saved data with source path
    logger.info('Creating model from data:', data);
    const modelConfig = {
      ...data,
      source: data.source || data.path, // Handle both source and path fields
      format: 'gguf'
    };
    logger.info('Model config:', modelConfig);
    const model = new GGUFModel(modelConfig);
    return model;
  }
}

export default GGUFLoader;

</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="ABTestingManager.html">ABTestingManager</a></li><li><a href="AuditLogger.html">AuditLogger</a></li><li><a href="AuthMiddleware.html">AuthMiddleware</a></li><li><a href="BPETokenizer.html">BPETokenizer</a></li><li><a href="BaseEngine.html">BaseEngine</a></li><li><a href="BaseLoader.html">BaseLoader</a></li><li><a href="BinaryLoader.html">BinaryLoader</a></li><li><a href="BinaryModel.html">BinaryModel</a></li><li><a href="BitNetLoader.html">BitNetLoader</a></li><li><a href="ConversionConfig.html">ConversionConfig</a></li><li><a href="ConversionResult.html">ConversionResult</a></li><li><a href="EnterpriseAuthManager.html">EnterpriseAuthManager</a></li><li><a href="EnterpriseManager.html">EnterpriseManager</a></li><li><a href="EnterpriseRouter.html">EnterpriseRouter</a></li><li><a href="FormatConverter.html">FormatConverter</a></li><li><a href="GGUFLoader.html">GGUFLoader</a></li><li><a href="GGUFModel.html">GGUFModel</a></li><li><a href="GRPCClient.html">GRPCClient</a></li><li><a href="LLMRouter.html">LLMRouter</a></li><li><a href="MockLoader.html">MockLoader</a></li><li><a href="MockModel.html">MockModel</a></li><li><a href="ModelInterface.html">ModelInterface</a></li><li><a href="ModelQuantizer.html">ModelQuantizer</a></li><li><a href="ModelTemplates.html">ModelTemplates</a></li><li><a href="MultiTenancyManager.html">MultiTenancyManager</a></li><li><a href="PyTorchLoader.html">PyTorchLoader</a></li><li><a href="PyTorchModel.html">PyTorchModel</a></li><li><a href="QuantizationConfig.html">QuantizationConfig</a></li><li><a href="QuantizationResult.html">QuantizationResult</a></li><li><a href="Router.html">Router</a></li><li><a href="SLAMonitor.html">SLAMonitor</a></li><li><a href="SentencePieceTokenizer.html">SentencePieceTokenizer</a></li><li><a href="SimpleLoader.html">SimpleLoader</a></li><li><a href="SimpleModel.html">SimpleModel</a></li><li><a href="TokenizationResult.html">TokenizationResult</a></li><li><a href="TokenizerConfig.html">TokenizerConfig</a></li><li><a href="UniversalTokenizer.html">UniversalTokenizer</a></li><li><a href="ValidationConfig.html">ValidationConfig</a></li><li><a href="ValidationSuite.html">ValidationSuite</a></li><li><a href="ValidationSuiteResult.html">ValidationSuiteResult</a></li><li><a href="ValidationTestResult.html">ValidationTestResult</a></li><li><a href="WordPieceTokenizer.html">WordPieceTokenizer</a></li></ul><h3>Global</h3><ul><li><a href="global.html#Architectures">Architectures</a></li><li><a href="global.html#AuditEventTypes">AuditEventTypes</a></li><li><a href="global.html#AuthMethods">AuthMethods</a></li><li><a href="global.html#BreachSeverity">BreachSeverity</a></li><li><a href="global.html#Capabilities">Capabilities</a></li><li><a href="global.html#ComplianceFrameworks">ComplianceFrameworks</a></li><li><a href="global.html#EnterpriseFeatures">EnterpriseFeatures</a></li><li><a href="global.html#ExperimentStatus">ExperimentStatus</a></li><li><a href="global.html#IsolationLevels">IsolationLevels</a></li><li><a href="global.html#ModelFormat">ModelFormat</a></li><li><a href="global.html#ModelFormats">ModelFormats</a></li><li><a href="global.html#Permissions">Permissions</a></li><li><a href="global.html#QuantizationMethod">QuantizationMethod</a></li><li><a href="global.html#QuantizationPrecision">QuantizationPrecision</a></li><li><a href="global.html#QuotaTypes">QuotaTypes</a></li><li><a href="global.html#RiskLevels">RiskLevels</a></li><li><a href="global.html#RoutingStrategies">RoutingStrategies</a></li><li><a href="global.html#SLAMetricTypes">SLAMetricTypes</a></li><li><a href="global.html#SLAStatus">SLAStatus</a></li><li><a href="global.html#SessionTypes">SessionTypes</a></li><li><a href="global.html#SplittingAlgorithms">SplittingAlgorithms</a></li><li><a href="global.html#StatisticalTests">StatisticalTests</a></li><li><a href="global.html#TimeWindows">TimeWindows</a></li><li><a href="global.html#TokenizerType">TokenizerType</a></li><li><a href="global.html#UserRoles">UserRoles</a></li><li><a href="global.html#ValidationSeverity">ValidationSeverity</a></li><li><a href="global.html#ValidationTestType">ValidationTestType</a></li><li><a href="global.html#colors">colors</a></li><li><a href="global.html#createEnterpriseExpressRoutes">createEnterpriseExpressRoutes</a></li><li><a href="global.html#createEnterpriseRouter">createEnterpriseRouter</a></li><li><a href="global.html#createEnterpriseWebSocketHandlers">createEnterpriseWebSocketHandlers</a></li><li><a href="global.html#defaultEnterpriseConfig">defaultEnterpriseConfig</a></li><li><a href="global.html#enterpriseVersion">enterpriseVersion</a></li><li><a href="global.html#errorMonitoringMiddleware">errorMonitoringMiddleware</a></li><li><a href="global.html#getEnabledFeatures">getEnabledFeatures</a></li><li><a href="global.html#getMonitoringStatus">getMonitoringStatus</a></li><li><a href="global.html#httpMonitoringMiddleware">httpMonitoringMiddleware</a></li><li><a href="global.html#isFeatureEnabled">isFeatureEnabled</a></li><li><a href="global.html#recordCustomMetric">recordCustomMetric</a></li><li><a href="global.html#registerAlertRule">registerAlertRule</a></li><li><a href="global.html#registerDependency">registerDependency</a></li><li><a href="global.html#registerHealthCheck">registerHealthCheck</a></li><li><a href="global.html#setupMonitoring">setupMonitoring</a></li><li><a href="global.html#startPerformanceProfile">startPerformanceProfile</a></li><li><a href="global.html#validateEnterpriseConfig">validateEnterpriseConfig</a></li><li><a href="global.html#withCacheMonitoring">withCacheMonitoring</a></li><li><a href="global.html#withDatabaseMonitoring">withDatabaseMonitoring</a></li><li><a href="global.html#withModelMonitoring">withModelMonitoring</a></li><li><a href="global.html#withQueueMonitoring">withQueueMonitoring</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 4.0.4</a> on Sun Aug 17 2025 22:28:58 GMT+0000 (Coordinated Universal Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
