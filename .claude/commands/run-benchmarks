#!/bin/bash

# üèÉ‚Äç‚ôÇÔ∏è LLM Runner Router - Performance Benchmarking Command
# Comprehensive performance testing for all providers

set -e

echo "üèÉ‚Äç‚ôÇÔ∏è LLM Runner Router Performance Benchmarking"
echo "================================================"

# Check if Node.js is available
if ! command -v node &> /dev/null; then
    echo "‚ùå Node.js is required but not installed"
    exit 1
fi

# Set environment variables for benchmarking
export NODE_ENV=test
export BENCHMARK_MODE=true

# Create benchmark results directory
mkdir -p benchmark-results

# Get current timestamp for results
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

echo "üìä Starting comprehensive benchmark suite..."
echo "Results will be saved to: benchmark-results/benchmark_${TIMESTAMP}.json"

# Run the benchmark script
node << 'EOF'
import { PerformanceBenchmark } from './src/utils/PerformanceBenchmark.js';
import { APILoader } from './src/loaders/APILoader.js';
import fs from 'fs';

async function runBenchmarks() {
  const benchmark = new PerformanceBenchmark();
  const results = [];
  
  // Test configurations for different providers
  const testConfigs = [
    {
      provider: 'openai',
      apiKey: process.env.OPENAI_API_KEY,
      model: 'gpt-3.5-turbo'
    },
    {
      provider: 'anthropic', 
      apiKey: process.env.ANTHROPIC_API_KEY,
      model: 'claude-3-haiku-20240307'
    },
    {
      provider: 'groq',
      apiKey: process.env.GROQ_API_KEY,
      model: 'mixtral-8x7b-32768'
    }
  ];

  console.log(`üî¨ Testing ${testConfigs.length} providers...`);

  for (const config of testConfigs) {
    if (!config.apiKey) {
      console.log(`‚ö†Ô∏è  Skipping ${config.provider} - no API key provided`);
      continue;
    }

    try {
      console.log(`\nüß™ Benchmarking ${config.provider}...`);
      
      const adapter = new APILoader({
        provider: config.provider,
        apiKey: config.apiKey
      });

      await adapter.load(config.model);

      const result = await benchmark.runBenchmarkSuite(adapter, {
        categories: ['simple', 'medium'],
        iterations: 3,
        warmup: 1,
        includeStressTest: false, // Disable for quick testing
        includeConcurrencyTest: true,
        concurrencyLevels: [1, 2]
      });

      results.push(result);
      console.log(`‚úÖ ${config.provider} completed - Grade: ${result.summary.overallGrade}`);

    } catch (error) {
      console.log(`‚ùå ${config.provider} failed: ${error.message}`);
      results.push({
        provider: config.provider,
        error: error.message,
        timestamp: new Date().toISOString()
      });
    }
  }

  // Generate comparison report
  if (results.filter(r => !r.error).length > 1) {
    console.log('\nüìä Generating comparison report...');
    const comparison = benchmark.compareProviders(results.filter(r => !r.error));
    
    console.log('\nüèÜ Performance Rankings:');
    console.log(`Latency (lower is better): ${comparison.rankings.latency.join(' > ')}`);
    console.log(`Throughput (higher is better): ${comparison.rankings.throughput.join(' > ')}`);
    console.log(`Success Rate (higher is better): ${comparison.rankings.successRate.join(' > ')}`);
  }

  // Save detailed results
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const filename = `benchmark-results/benchmark_${timestamp}.json`;
  
  fs.writeFileSync(filename, JSON.stringify({
    timestamp: new Date().toISOString(),
    systemInfo: await benchmark.getSystemInfo(),
    results,
    comparison: results.filter(r => !r.error).length > 1 ? 
      benchmark.compareProviders(results.filter(r => !r.error)) : null
  }, null, 2));

  console.log(`\nüíæ Results saved to: ${filename}`);
  console.log('\nüéØ Summary:');
  
  results.forEach(result => {
    if (result.error) {
      console.log(`  ${result.provider}: ‚ùå ${result.error}`);
    } else {
      const avgLatency = result.summary.averageMetrics.latency;
      const throughput = result.summary.averageMetrics.throughput;
      const successRate = (result.summary.averageMetrics.successRate * 100).toFixed(1);
      
      console.log(`  ${result.provider}: ${result.summary.overallGrade.toUpperCase()} (${avgLatency}ms, ${throughput} tok/s, ${successRate}% success)`);
    }
  });

  console.log('\n‚ú® Benchmark complete!');
}

runBenchmarks().catch(console.error);
EOF

echo ""
echo "üìà To analyze results further:"
echo "  - Check benchmark-results/ directory for detailed JSON reports"
echo "  - View latest results: cat benchmark-results/benchmark_*.json | jq '.comparison'"
echo "  - Run with specific providers: OPENAI_API_KEY=xxx GROQ_API_KEY=yyy ./run-benchmarks"
echo ""
echo "üéØ Benchmark categories tested:"
echo "  - Simple prompts (basic conversational)"
echo "  - Medium prompts (explanatory tasks)"
echo "  - Concurrency tests (1-2 simultaneous requests)"
echo ""
echo "‚úÖ Benchmarking complete!"